# @beerose/semantic-search

An OpenAI-powered CLI to build a semantic search index from your MDX files. It
allows you to perform complex searches across your content and integrate it with
your platform.

## ğŸš€ CLI Usage

```sh
$ @beerose/semantic-search
```

### ğŸ›  Commands:

`index <dir>` â€” processes files with your content and upload them to Pinecone.

Example:

```sh
$ @beerose/semantic-search index ./posts
```

`search <query>` â€” performs a semantic search by a given query.

Example:

```sh
$ @beerose/semantic-search search "hello world"
```

For more info, run any command with the `--help` flag:

```sh
$ @beerose/semantic-search index --help
$ @beerose/semantic-search search --help
$ @beerose/semantic-search --help
```

## â• Project integration

You can use the `semanticQuery` function exported from this library and
integrate it with your website or application.

An example usage:

```ts
import { PineconeMetadata, semanticQuery } from "@beerose/semantic-search";
import { Configuration, OpenAIApi } from "openai";
import { PineconeClient } from "pinecone-client";

const openai = new OpenAIApi(
  new Configuration({
    apiKey: process.env.OPENAI_API_KEY,
  })
);

const pinecone = new PineconeClient<PineconeMetadata>({
  apiKey: process.env.PINECONE_API_KEY,
  baseUrl: process.env.PINECONE_BASE_URL,
  namespace: process.env.PINECONE_NAMESPACE,
});

const result = await semanticQuery("hello world", openai, pinecone);
```

## âœ¨ How does it work?

Semantic search is a system that can understand the meaning of words in
documents and return results that are more relevant to the user's intent.

This tool uses [OpenAI](https://openai.com/) to generate vector embeddings with
a `text-embedding-ada-002` model.

> Embeddings are numerical representations of concepts converted to number
> sequences, which make it easy for computers to understand the relationships
> between those concepts.
> https://openai.com/blog/new-and-improved-embedding-model/

It also uses [Pinecone](https://pinecone.io/) â€” a hosted database for vector
search. It lets us perform k-NN searches across the generated embeddings.

### Processing MDX content

The `@beerose/sematic-search index` CLI command performs the following steps for
each file in a given directory:

1.  Converts the MDX files to raw text.
2.  Extracts the title.
3.  Splits the file into chunks of a maximum of 100 tokens.
4.  Generates OpenAI embeddings for each chunk.
5.  Upserts the embeddings to Pinecone.

Depending on your content, the whole process requires a bunch of calls to OpenAI
and Pinecone, which can take some time. For example, it takes around thirty
minutes for a directory with ~25 blog posts and an average of 6 minutes of
reading time.

### Performing semantic searches

To test the semantic search, you can use `@beerose/sematic-search search` CLI
command, which:

1. Creates an embedding for a provided query.
2. Sends a request to Pinecone with the embedding.

## ğŸ“¦ What's inside?

```sh
.
â”œâ”€â”€ bin
â”‚   â””â”€â”€ cli.js
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ bin
â”‚   â”‚   â””â”€â”€ cli.ts
â”‚   â”œâ”€â”€ commands
â”‚   â”‚   â”œâ”€â”€ indexFiles.ts
â”‚   â”‚   â””â”€â”€ search.ts
â”‚   â”œâ”€â”€ getEmbeddings.ts
â”‚   â”œâ”€â”€ isRateLimitExceeded.ts
â”‚   â”œâ”€â”€ mdxToPlainText.test.ts
â”‚   â”œâ”€â”€ mdxToPlainText.ts
â”‚   â”œâ”€â”€ semanticQuery.ts
â”‚   â”œâ”€â”€ splitIntoChunks.test.ts
â”‚   â”œâ”€â”€ splitIntoChunks.ts
â”‚   â”œâ”€â”€ titleCase.ts
â”‚   â””â”€â”€ types.ts
â”œâ”€â”€ tsconfig.build.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ package.json
â””â”€â”€ pnpm-lock.yaml
```

- `bin/cli.js` â€” The CLI entrypoint.
- `src`:
  - `bin/cli.ts` â€” Files where you can find CLI commands and settings. This
    project uses [CAC](https://github.com/cacjs/cac) for building CLIs.
  - `commands/indexFiles.ts` â€” A CLI command that handles processing md/mdx
    content, generating embeddings and uploading vectors to Pinecone.
  - `command/search.ts` â€” A semantic search command. It generates an embedding
    for a given search query and then calls Pinecone for the results.
  - `getEmbeddings.ts` â€” Generating embeddings logic. It handles a call to Open
    AI.
  - `isRateLimitExceeded.ts` â€” Error handling helper.
  - `mdxToPlainText.ts` â€” Converts MDX files to raw text. Uses remark and a
    custom `remarkMdxToPlainText` plugin (also defined in that file).
  - `semanticQuery.ts` â€” Core logic for performing semantic searches. It's being
    used in `search` command, and also it's exported from this library so that
    you can integrate it with your projects.
  - `splitIntoChunks.ts` â€” Splits the text into chunks with a maximum of 100
    tokens.
  - `titleCase.ts` â€” Extracts a title from a file path.
  - `types.ts` â€” Types and utilities used in this project.
- `tsconfig.json` - TypeScript compiler configuration.
- `tsconfig.build.json` - TypeScript compiler configuration used for
  `pnpm build`.

Tests:

- `src/mdxToPlainText.test.ts`
- `src/splitIntoChunks.test.ts`

## ğŸ‘©â€ğŸ’» Local development

Install deps and build the project:

```sh
pnpm i

pnpm build
```

Run the CLI:

```sh
node bin/cli.js
```

## ğŸ§ª Running tests

```sh
pnpm test
```

## ğŸ¤ Contributing

Contributions, issues and feature requests are welcome.<br /> Feel free to check
[issues page](https://github.com/beerose/semantic-search/issues) if you want to
contribute.<br />

## ğŸ“ License

Copyright Â© 2023 [Aleksandra Sikora](https://github.com/beerose).<br /> This
project is [MIT](https://github.com/beerose/semantic-search/blob/master/LICENSE)
licensed.
